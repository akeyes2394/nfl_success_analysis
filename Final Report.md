# Modeling NFL Success of New Players

The goal of this project was to take data on NFL player's college careers and performance, and create a model that would predict how well they would perform upon their first few years in the NFL.  

## Data Sources and Scraping Methodology

The data sources for this project are [pro-football-reference.com](https://www.pro-football-reference.com/), [sports-reference.com](https://www.sports-reference.com), and [profootballfocus.com](https://www.profootballfocus.com/).  

More specifically [this](https://www.pro-football-reference.com/years/2018/draft.htm) page was used to scrape players drafted into the NFL going back a number of years along with data included in their draft table.  To do this I used Beautful Soup to parse out the HTML code on each page, looping through the pages by changing the the year from 2018 to 2017 for example in the URL.  

Included in this table was a link to each player's college statistics which I used for the next step in my scraping.  As I scraped each draft table, I saved this [College Stats](https://www.sports-reference.com/cfb/players/baker-mayfield-1.html) URL for each player.  Once I had that URL saved for each player in my dataframe, I looped through that column and used the URL to extract HTML code for that player's college stats, and once again used Beautiful Soup to parse the data out of the HTML

This scraping proved to be quite difficult as each player had a slightly different layout of their college stats page.  However after a few iterations of building a scraper I made my approach dynamic, pulling the tables out of the HTML and looping over the number of tables on that given page to grab all relevant information.  One note on this that made it especially tricky, is that there seemed to be some buggy code, or display error with the HTML, that made the code for all the tables but the first one on a given page appear in a comment form, so that it was irretrievable from the HTML code from the original page.  To access it I had to find the comment in the original BeautifulSoup object, and then repass that comment into another BeautifulSoup object so I could access those tables.  

Finally I used [profootballfocus.com](https://www.profootballfocus.com/)'s player grades as my target variable to model the rest of my data on.  I did not scrape these but rather downloaded CSV files for the years and positions I needed.  This site offeres position grades as well as other data such as games played for a given year that I was able to leverage in my model.  

## Data Processing and Cleaning

I simply read the CSV files I downloaded with player grades into dataframe format, and aggregated them together by category, saving the player name and the year into a unique key column that I could later use to map a specific year's player grade to my larger dataframe with all the NFL draft picks.  

At this point as I am starting to bring all my data together into the one draft picks data frame I chose to drop two subsets of data.  First I drop data that does not have a URL for college stats in my dataframe, as some of the player data I scraped off of pro-football-reference did not have associated college stats records.  Since I cannot use these players in my model I dropped those datapoints.  I also choose to drop players of positions I deemed irrelevant because they had few or no stats associated with their college careers (such as Offensive Linemen, or Punters) on their college stats page, so modeling these positions would be impossible. 

Next as mentioned above, I joined the player grades data to my draft picks dataframe, adding columns for the player's grade in each of the first four years after they were drafted, as well as the number of games the player played that year.  I chose to examine four years because generally rookie contracts in the NFL are 3-4 years in length, so this was a natural fit for a length of time to examine whether or not a player will be successful, or bust.  

In dealing with null values I chose to fill nulls  in my college stats dataframe with 0 values, because the assumption is that if it was not included on a table on pro-football-reference.com there were not stats accumulated in that category that year for that player.  Rather than having a table full of zeros for multiple categories, that website opted to just have those specific categories missing.  Because of this I have to assume those values are zeros for those players, however this could be a limitation of my modeling later on, and other than manually checking and imputing values I don't really have a way of knowing whether or not a stat is actually missing, or just not accumulated that season meaning it would be a zero. 

When joining my college stats data to my draft picks dataframe, I had to decide how to deal with the multiple datapoints I had for each college player, those being each year of their college career.  I chose to create two dataframes from the larger college stats dataframe that I have, those being avg_college_stats and final_year_college_stats, as these would be my way of creating one single datapoint for each player that I could map to my draft_picks, rather than having multiple lines for different years of college stats.  Later on in modeling I opt to use the avg_college_stats over final_year_college_stats. 

I am now almost done with the data processing step, I just finally need to make my target variable, the player grade, a single value.  I am created one average grade as an average of a players first four years grades in the NFL.  I created logic such that if a player didn't play in a given year ('games_y1 would be null for example) or they played less than 5 games that year, then that year would not be included in the average.

## Modeling and Conclusions

Overall the modeling could have gone a lot better.  The biggest limitation I had is the amount of data I was working with.  I began with what I thought was a fairly substantial amount of data but steadily lost data along the way during processing.  Certain positions from my original draft scrape were irrelevant simply due to the fact that they do not accumulate significant statistics (Offensive Line, Punters), certain players whose positions were relevant didn't have records of their college stats for reasons unknown on pro-football-reference.com, or the HTML on their page had a strange enough structure to trigger an error and get passed over even with my dynamic scraper.  

Regardless of the reason I was only working with about 1500 observations with full and complete data when I got to modeling.  This doesn't seem that bad at first, but when I tried my most simplistic approach by passing all my columns and all positions into one model, trying a basic Linear Regression, a Random Forest, and a Neural Net, my R2 scores and MSE scores were very poor.  I tried adding dummy variables for the columns representing the players college conference, the NFL they were drafted to, and their position.  This helped a bit in the Random Forest model, but not a ton.  

I then tried a few approaches next.  I chose to drop all of the 'final_year' columns as I had over 150 columns and thought simplifying my variables might help a bit, and remove some colinearity.  Also I was thinking I would have to try this anyways, but I decided to split the dataframe up by position (QB, RB, Receiver, Defense) and build separate models by position.  This helped my modeling a fair bit- my models still weren't great but they were better that my broader models that I made first, and could likely be improved upon.  

The results varied by position, but generally the Quarterback and Reciever models worked better than the Running Back and Defense models.  My MSE scores ranged from around 600-800 which again aren't great and should be improved upon with further analysis.  My best score on the Neural Net I ran on my receiving dataframe was an MSE of just about 580.  This comes out to an error term of just about 24 points, meaning that on average my predictions were within 24 points of the actual position grade assigned on profootballfocus.com.  Essentially my model would be able to predict a good player would be good, and a bad player would be bad fairly certainly, however any borderline players who are somewhere in the middle, my model will predict on poorly.  

[Model Residuals](https://github.com/akeyes2394/nfl_success_analysis/blob/master/data/Model_Residuals.png)

## Further Analysis and Follow Up

This study has really just scratched the surface of what is possible on this subject.  There are a number of different things that I would have and will do with more time.  First and foremost would be to get more data.  I was hesitant to go too far back in the draft, I stopped after ten years, as I figured there have been fairly significant changes to the game of football over the past two decades, mainly the league shifting to more of a offensive and passing league.  To do a thorough study of this I believe you have to go back further than 10 years or get much more complete data than I did, as using the number of players I had is simply not effective.  When I split my small number of observations further by creating models for each position, for my Quarterback model I had less than 100 observations, without even splitting my train and test data out on the last three years.  Having more data would certainly help model performance, and I could create some kind of decade dummy variable to try and capture some of the variance created by changes to the NFL over time.  

I also had a ton of variables in my dataset that I was modeling over, so there is likely a fair bit of colinearity between variables since a lot of them are related, as well as a good bit of noise overall.  Doing some kind of feature selections such as a Ridge or Lasso regression, or PCA would hopefully help draw some of the more important factors out of the noise.  

Finally I know there are more variables I could include beyond just performance numbers from college games.  One that springs to mind specifically that I did not use that I certainly would have liked to given more time is combine numbers, such as 40-yard dash, high jump, broad jump, height, weight etc.  